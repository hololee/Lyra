from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from typing import List
from ..database import get_db
from ..models import Environment
from ..schemas import EnvironmentCreate, EnvironmentResponse
from ..tasks import create_environment_task
import docker

router = APIRouter(
    prefix="/environments",
    tags=["environments"],
)


@router.post("/", response_model=EnvironmentResponse, status_code=status.HTTP_201_CREATED)
async def create_environment(env: EnvironmentCreate, db: AsyncSession = Depends(get_db)):
    # Logic to find available ports and GPUs will go here
    # For now, we will mock these values

    # Mock allocation (In real logic, we should scan available ports)
    # Using random ports to avoid conflict for demo
    import random
    import pynvml

    # Real GPU Allocation Logic
    gpu_indices = []
    if env.gpu_count > 0:
        total_gpus = 0
        try:
            pynvml.nvmlInit()
            total_gpus = pynvml.nvmlDeviceGetCount()
            pynvml.nvmlShutdown()
        except Exception:
            # If NVML fails, assume 0 or handle accordingly
            raise HTTPException(status_code=500, detail="Failed to detect GPUs on host")

        # Find currently used GPUs
        result = await db.execute(select(Environment).where(Environment.status.in_(["running", "building"])))
        active_envs = result.scalars().all()
        used_indices = set()
        for active in active_envs:
            if active.gpu_indices:
                used_indices.update(active.gpu_indices)

        # Find available indices
        available_indices = [i for i in range(total_gpus) if i not in used_indices]

        if len(available_indices) < env.gpu_count:
            raise HTTPException(
                status_code=400,
                detail=f"Not enough GPUs available. Requested: {env.gpu_count}, Available: {len(available_indices)}"
            )

        # Allocate
        gpu_indices = available_indices[:env.gpu_count]

    mock_gpu_indices = gpu_indices
    mock_ssh_port = random.randint(20000, 25000)
    mock_jupyter_port = random.randint(25001, 30000)
    mock_code_port = random.randint(30001, 35000)

    # In a real implementation, we would lock rows to prevent race conditions

    new_env = Environment(
        name=env.name,
        container_user=env.container_user,
        root_password=env.root_password,
        dockerfile_content=env.dockerfile_content,
        mount_config=[m.dict() for m in env.mount_config],
        gpu_indices=mock_gpu_indices,
        ssh_port=mock_ssh_port,
        jupyter_port=mock_jupyter_port,
        code_port=mock_code_port,
        status="building"
    )

    db.add(new_env)
    await db.commit()
    await db.refresh(new_env)

    # Trigger Celery Task
    create_environment_task.delay(new_env.id)

    return new_env


@router.get("/", response_model=List[EnvironmentResponse])
async def read_environments(skip: int = 0, limit: int = 100, db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Environment).offset(skip).limit(limit))
    envs = result.scalars().all()

    # Sync with Docker status
    client = docker.from_env()
    status_changed = False

    for env in envs:
        container_name = f"lyra-{env.name}-{env.id}"
        try:
            container = client.containers.get(container_name)

            # Check for error state (Exit Code != 0)
            exit_code = container.attrs['State'].get('ExitCode', 0)

            if container.status == 'running':
                if env.status != 'running':
                    env.status = 'running'
                    status_changed = True
            else:
                # Container is not running
                new_status = 'stopped'
                if exit_code != 0:
                    new_status = 'error'

                if env.status != new_status:
                    env.status = new_status
                    status_changed = True
        except docker.errors.NotFound:
            if env.status in ['running', 'building']:
                # If it was supposed to be running/building but not found, mark as stopped or error
                # Note: 'building' might be tricky if it's still in image build phase,
                # but once container is expected, it should be there.
                # For simplicity, if not found and was running, mark stopped.
                if env.status == 'running':
                    env.status = 'stopped'
                    status_changed = True
        except Exception as e:
            print(f"Error checking container status: {e}")

    if status_changed:
        await db.commit()
        # Re-fetch or just return updated objects (SQLAlchemy objects act as refs)

    return envs


@router.get("/{environment_id}", response_model=EnvironmentResponse)
async def read_environment(environment_id: str, db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Environment).where(Environment.id == environment_id))
    env = result.scalars().first()
    if env is None:
        raise HTTPException(status_code=404, detail="Environment not found")
    return env


@router.delete("/{environment_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_environment(environment_id: str, db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(Environment).where(Environment.id == environment_id))
    env = result.scalars().first()
    if env is None:
        raise HTTPException(status_code=404, detail="Environment not found")

    # Try to remove container
    try:
        client = docker.from_env()
        container_name = f"lyra-{env.name}-{env.id}"
        try:
            container = client.containers.get(container_name)
            container.remove(force=True)
        except docker.errors.NotFound:
            pass  # Container already gone
    except Exception as e:
        print(f"Error removing container: {e}")

    await db.delete(env)
    await db.commit()

    return None
